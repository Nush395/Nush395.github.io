---
layout: post
title: "Understanding TrueSkill"
date: 2020-06-06
---
<h2>
    Overview
</h2>
<p>
    This is a post to document the learnings I made on my several week journey to understanding the
    TrueSkill algorithm created by Microsoft Research for ranking teams of players in games. This post
    is an accompaniment to the <a href="https://github.com/Nush395/TrueSkill">library</a> I created
    where I replicated the
    <a href="https://www.microsoft.com/en-us/research/publication/trueskilltm-a-bayesian-skill-rating-system/">
        original paper.
    </a>
    Along with the original paper another really helpful resource I found is this
    <a href="https://www.moserware.com/assets/computing-your-skill/The%20Math%20Behind%20TrueSkill.pdf">
        article
    </a>
    by Jeff Moser which explains a lot of the detail behind the equations in the original paper.
</p>
<h2>
    Introduction
</h2>
<p>
    We want to model players' skills, that is some attribute of a players that can be used to compare the
    probability that one will win against another and predict a games' outcome. To illustrate this we can
    build a model for the outcome of a game involving two players.
</p>
<p>
    <ul>
        <li>
            Take Player 1 to have skill $w_1$ and  Player 2 to have skill $w_2$ ($w_i \in \mathbb{R}$).
        </li>
        <li>
            Compute the difference in the player skills: $s = w_1 - w_2$.
        </li>
        <li>
            Add some Gaussian noise ($n \sim \mathcal{N}(0,\,\sigma^{2}$)) to account for the uncertainty in the match:
            $t=s+n$.
        </li>
        <li>
            The game outcome will be determined by $y=sign(t)$; $y=1$ implies Player 1 won and $y=-1$ implies Player 2 won.
        </li>
    </ul>
</p>
<p>
    We can take a Bayesian treatment of this model by placing a prior probability over the
    initial skills and then use the observed game outcome to compute the posterior probability
    of the skills given the game outcome. Let's go ahead and do that then...
    <ol>
        <li>
            Choosing a Gaussian distribution to represent the prior probabilities we have:
            $$w_i \sim \mathcal{N}(\mu_u,\,\sigma_i^{2})$$
        </li>
        <li>
            If we take the game noise to have standard deviation of 1, $n \sim \mathcal{N}(0,\,1)$ for simplicity then,
            the likelihood is given by $p(y|w_1,w_2) = \Phi(y(w_1-w_2))$
            <button data-toggle="collapse" data-target="#likelihood-derivation">Likelihood derivation</button>
            <div id="likelihood-derivation" class="collapse">
                $$t = w_1 - w_2 + n \Rightarrow p(t|w_1,w_2) = \mathcal{N}(w_1-w_2,\,1)$$
                As y is a binary variable let's work out each case:
                $$p(y=1|w_1,w_2) = p(t>0|w_1,w_2) = \Phi(w_1-w_2)$$
                $$p(y=-1|w_1,w_2) = p(t<0|w_1,w_2) = 1 - \Phi(w_1-w_2) = \Phi(-(w_1-w_2))$$
                $$\therefore p(y|w_1,w_2) = \Phi(y(w_1-w_2))$$
            </div>
        </li>
    </ol>
</p>

